{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dvlncHjZRYh_",
        "DSfPZe7t4lk3",
        "h1SetpCFTlt4",
        "jM77wOW7MmS9",
        "b-GbVxD3RGCR",
        "JxzVVzilJ0mn",
        "MPIv3WuU6ApY",
        "HtdPTA802Xq5"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPnt+ocOH9tQV7CjpJxyM4f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omer-lebel/Perceptron-Linear-Logistic-Regression-From-Scratch/blob/main/Linear_ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Machine Learning Models\n",
        "By Omer Lebel <br>\n",
        "(with the kind help of all the AI â€‹â€‹assistants the world currently has to offer ðŸ˜‰ )"
      ],
      "metadata": {
        "id": "3Tyc4M8zEIol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ Prepration\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dvlncHjZRYh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST dataset containe a collection of 70,000 labeled images of handwritten digits (0-9)\n",
        "\n",
        "*   **Image size:** Each image is 28X28 pixel, resulting in a total of 784 pixel per imape.\n",
        "*   **Grayscale:** The impages are greyscal, eith each pixel represented by a single intesity ranging from 0 (black) to 255 (white)\n",
        "\n",
        "We will spilt the dataset into training set of 60,000 image, and test set of 10,000 images."
      ],
      "metadata": {
        "id": "6WtpLwpQ92n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.ticker as mtick"
      ],
      "metadata": {
        "id": "uY73BfXr6LZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy8S88yBtOGb"
      },
      "outputs": [],
      "source": [
        "TEST_SIZE = 10000\n",
        "\n",
        "# fetch MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "X, y = mnist['data'], mnist['target'] # X - data, Y - labels\n",
        "m_samples, n_features = X.shape\n",
        "\n",
        "# convert X to matrix 70k*784 and adding bias (col of 1s) to X\n",
        "X = X.to_numpy()\n",
        "X_with_bias = np.c_[X, np.ones(X.shape[0])]\n",
        "\n",
        "# one hot encoding y (y_one_hot[i,j] = 1 if y[i] == j else 0)\n",
        "y = y.to_numpy().astype(int)\n",
        "y_one_hot = np.zeros((m_samples, 10), dtype=int)\n",
        "y_one_hot[np.arange(m_samples), y] = 1\n",
        "\n",
        "# spliting the data set into train and test\n",
        "X_train, X_test, y_train_onehot, y_test_onehot = train_test_split(\n",
        "    X_with_bias, y_one_hot, test_size = TEST_SIZE, random_state=0)\n",
        "\n",
        "# one hot encoding with -1 instead of 0\n",
        "y_signed_train = np.where(y_train_onehot == 1, 1, -1)\n",
        "y_signed_test = np.where(y_test_onehot == 1, 1, -1)\n",
        "\n",
        "# y_true[i] = true digit of sample i\n",
        "y_test_true = np.argmax(y_test_onehot, axis=1).astype(int)\n",
        "y_train_true = np.argmax(y_train_onehot, axis=1).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš’ Utils\n"
      ],
      "metadata": {
        "id": "DSfPZe7t4lk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* confustion matrix\n",
        "* accuracy score: ACC = âˆ‘TPáµ¢ / (numer of samples)\n",
        "* recall / sensitivity: TPR = TP/(TP+FN)"
      ],
      "metadata": {
        "id": "3A68H-_qFy9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def confusion_matrix(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  for both binary and molticlass\n",
        "  \"\"\"\n",
        "\n",
        "  # init the matrix\n",
        "  num_classes = max(np.max(y_true), np.max(y_pred)) + 1  # assume labesl are 0-index\n",
        "  conf_matrix = np.zeros((num_classes,num_classes), dtype=int)\n",
        "\n",
        "  # perform conf_matrix[true_label, pred_label] += 1\n",
        "  np.add.at(conf_matrix, (y_true, y_pred), 1)\n",
        "\n",
        "   # if it's binary classification, rearrange the matrix\n",
        "  if num_classes == 2:\n",
        "    TP, TN, FP, FN = conf_matrix[1, 1], conf_matrix[0, 0], conf_matrix[0, 1], conf_matrix[1, 0]\n",
        "    conf_matrix = np.array([[TP, FN], [FP, TN]])\n",
        "\n",
        "  return conf_matrix\n",
        "\n",
        "\n",
        "def accuracy_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  binary:     ACC = (TP+TN)/(numer of samples)\n",
        "  multyclass: ACC =  âˆ‘TPáµ¢ / (numer of samples)\n",
        "  \"\"\"\n",
        "  return np.sum(y_pred == y_true) / y_true.shape[0]\n",
        "\n",
        "\n",
        "def recall_score(y_true, y_pred): # aka TPR \\ sensitivity\n",
        "  \"\"\"\n",
        "  Suit only for binary classification\n",
        "  \"\"\"\n",
        "  TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "  FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "  return TP / (TP + FN)\n"
      ],
      "metadata": {
        "id": "OKvnR0lmJM7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph and matric ploting\n",
        "* plot multicalss confusion matrix\n",
        "* plot 10 confution matrix side by side"
      ],
      "metadata": {
        "id": "7vkbd4Q4Ge8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_multiclass_confusion_matrix(conf_matrix, title=\"Confusion Matrix Heatmap\"):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Reds\",\n",
        "                xticklabels=range(10), yticklabels=range(10))\n",
        "    plt.xlabel(\"Predicted Label\", fontsize=12)\n",
        "    plt.ylabel(\"True Label\", fontsize=12)\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_confusion_matrices_side_by_side(conf_matrices_lst, title=\"Digit-wise Confusion Matrices\"):\n",
        "\n",
        "  colors = ['YlOrBr', 'OrRd', 'YlOrRd', 'PuRd', 'RdPu', 'BuPu',\n",
        "            'GnBu', 'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']\n",
        "\n",
        "  # Create a figure with 2 rows and 5 columns\n",
        "  fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "\n",
        "  for digit, conf_matrix in enumerate(conf_matrices_lst):\n",
        "    ax = axes[digit // 5, digit % 5]  # Access the correct subplot\n",
        "    ax.set_title(f'Digit {digit}')\n",
        "\n",
        "    #add the heatmap\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=colors[digit], ax=ax,\n",
        "                xticklabels=[\"True\", \"False\"], yticklabels=[\"True\", \"False\"], cbar=False)\n",
        "    ax.set_xlabel(\"Predicted labels\")\n",
        "    ax.set_ylabel(\"True labels\")\n",
        "\n",
        "  fig.suptitle(title, fontsize=24)\n",
        "\n",
        "  # add padding and scases\n",
        "  plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "  plt.tight_layout(pad=2.0)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "j-nm7ZxzGeAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  Perceptron\n"
      ],
      "metadata": {
        "id": "h1SetpCFTlt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "  def __init__(self, max_iter=1000, interval_snapshot=50):\n",
        "    self.max_iter = max_iter\n",
        "    self.interval_snapshot = interval_snapshot\n",
        "    self._w = None\n",
        "    self._train_history = [] # track w_pocket and E_in\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    m_samples, n_features = X.shape\n",
        "\n",
        "    self._w = np.zeros(n_features)\n",
        "    w_pocket = self._w.copy()\n",
        "    min_E_in = np.inf\n",
        "    y_pred = self.predict(X)\n",
        "\n",
        "    for i in tqdm(range(self.max_iter), desc= f'train with pocket algo'):\n",
        "      # find random misclassified sample\n",
        "      Xi, Yi = self._find_misclassified_sample(X, y, y_pred)\n",
        "      if Xi is None: # no errors\n",
        "        break\n",
        "\n",
        "      # update w\n",
        "      self._w += Yi*Xi\n",
        "\n",
        "      # calculte the new E_in\n",
        "      y_pred = self.predict(X)\n",
        "      curr_E_in = self.Ein(y, y_pred)\n",
        "\n",
        "      # update w_pocket if neaded\n",
        "      if curr_E_in < min_E_in:\n",
        "        w_pocket = self._w.copy()\n",
        "        min_E_in = curr_E_in\n",
        "\n",
        "      self._track_train_progress(i, w_pocket, min_E_in)\n",
        "\n",
        "    self._w = w_pocket\n",
        "\n",
        "\n",
        "  def predict(self, X, w=None):\n",
        "    w = self._w if w is None else w\n",
        "    return np.sign(X @ w)\n",
        "\n",
        "  def get_w(self):\n",
        "    return self._w\n",
        "\n",
        "  def get_train_history(self):\n",
        "    return self._train_history\n",
        "\n",
        "  def Ein(self, y, y_pred):\n",
        "    return np.sum(y_pred != y) / y.shape[0]\n",
        "\n",
        "\n",
        "  def _find_misclassified_sample(self, X, y, y_pred):\n",
        "    # identify misclassified sample indexes\n",
        "    misclassified_indexes = np.where(y_pred != y)[0]\n",
        "\n",
        "    # return a random misclassified sample, if any\n",
        "    if misclassified_indexes.size > 0:\n",
        "      random_index  = np.random.choice(misclassified_indexes)\n",
        "      return X[random_index], y[random_index]\n",
        "\n",
        "    return None, None\n",
        "\n",
        "  def _track_train_progress(self, itr, w_pocket, cur_min_Ein):\n",
        "    if itr % self.interval_snapshot == 0 or itr == self.max_iter - 1:\n",
        "      self._train_history.append((itr, w_pocket, cur_min_Ein * 100))"
      ],
      "metadata": {
        "id": "WRTGnm5qDn5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Note:** in order to find missplaces sample, we use the previus calculeing of y_pred that has been done in order to calcuclute E_in."
      ],
      "metadata": {
        "id": "cn3lXkJJ9_gt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass classifier (one-vs-all)** <br>\n",
        "We will create 10 binary classifier - one for each digit (0 to 9). Then we'ill use the one-ve-all strategy : `h(x) = argmax(wáµ€x)`\n",
        "\n"
      ],
      "metadata": {
        "id": "A8QGqlASgc9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneVsAllPerceptron:\n",
        "  def __init__(self, max_iter=1000, interval_snapshot=50):\n",
        "    self.max_iter = max_iter\n",
        "    self.interval_snapshot = interval_snapshot\n",
        "    self._classifiers = []\n",
        "    self._W = None\n",
        "    self._multiclass_train_history = []\n",
        "    self._binary_train_history = []\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    m_samples, n_features = X.shape\n",
        "    k_classes = Y.shape[1] # assume Y is one-hot sign matrix\n",
        "\n",
        "    self._W = np.empty((n_features, 0))\n",
        "    errors_track  = []\n",
        "    w_track = []\n",
        "    snapshot_itr = 0\n",
        "\n",
        "    for class_idx in tqdm(range(k_classes), desc='train binary perceptron calssifier'):\n",
        "      # Train a binary classifier for the current class\n",
        "      clf = Perceptron(self.max_iter)\n",
        "      clf.fit(X, Y[:, class_idx]) # use the idx-th col of Y\n",
        "\n",
        "      # store the weights\n",
        "      self._classifiers.append(clf)\n",
        "      self._W = np.column_stack([self._W, clf.get_w()])\n",
        "\n",
        "      # track history\n",
        "      snapshot_itr, w_history , Ein_history = zip(*clf.get_train_history())\n",
        "      errors_track.append(Ein_history)\n",
        "      w_track.append(w_history)\n",
        "\n",
        "    self._multiclass_train_history = self.combine_history(\n",
        "        snapshot_itr, errors_track, w_track, k_classes)\n",
        "\n",
        "  def predict(self, X, W=None):\n",
        "    W = self._W if W is None else W\n",
        "    return np.argmax(X @ W, axis=1)\n",
        "\n",
        "  def get_W(self):\n",
        "    return self._W\n",
        "\n",
        "  def get_classifiers(self):\n",
        "    return self._classifiers\n",
        "\n",
        "  def Ein(self, y, y_pred):\n",
        "    return np.sum(y_pred != y) / y.shape[0]\n",
        "\n",
        "  def combine_history(self, iter, errors_track, w_track, k_classes):\n",
        "    errors_track = np.array(errors_track)\n",
        "    mean_error = np.mean(errors_track, axis=0)\n",
        "\n",
        "    stack_W_track = []\n",
        "    for snapshot_idx in tqdm(range(len(iter)), desc=\"combine W trackin\"):\n",
        "      # Select the snapshot_idx-th column from each row of w_track\n",
        "      W = np.column_stack([w_track[class_idx][snapshot_idx]\n",
        "                            for class_idx in range(k_classes)])\n",
        "      stack_W_track.append(W)\n",
        "\n",
        "    return [iter, stack_W_track, mean_error]\n",
        "\n",
        "  def get_multiclass_train_history(self):\n",
        "    return self._multiclass_train_history\n"
      ],
      "metadata": {
        "id": "R4jeWARoPrvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train <br>"
      ],
      "metadata": {
        "id": "4lLz4t4AFF2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function to show model convergence\n",
        "\n",
        "def plot_multiclass_perceptron_convergence(clf, interval_snapshot):\n",
        "  train_history = clf.get_multiclass_train_history()\n",
        "  iter, W_history , avg_binary_errors = train_history[0], train_history[1], train_history[2]\n",
        "\n",
        "  test_errors, train_errors = calc_multiclass_errors_during_train(clf, W_history)\n",
        "\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.plot(iter, avg_binary_errors, marker='o', linestyle='-', color='green', label='mean loss of binary classifiers on train set')\n",
        "  plt.plot(iter, test_errors, marker='o', linestyle='-', color='orange', label='test')\n",
        "  plt.plot(iter, train_errors, marker='o', linestyle='-', color='blue', label='train')\n",
        "  plt.title(f\"Mean loss of Multiclass Clf During Training\")\n",
        "  plt.xlabel(f\"Iteration (snapshot every {interval_snapshot} iteration)\")\n",
        "  plt.ylabel(f\"Error percentage (%)\")\n",
        "\n",
        "  formatter = mtick.PercentFormatter()\n",
        "  plt.gca().yaxis.set_major_formatter(formatter) #add % to ylabel\n",
        "  plt.grid(True)\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def calc_multiclass_errors_during_train(clf, W_history):\n",
        "  test_errors = []\n",
        "  train_errors = []\n",
        "\n",
        "  for i in tqdm(range(len(W_history)), desc=\"calculte multiclass errors throughout train\"):\n",
        "    W = np.array(W_history[i])\n",
        "\n",
        "    y_train_preds = clf.predict(X_train, W)\n",
        "    train_errors.append(clf.Ein(y_train_preds,y_train_true) * 100)\n",
        "\n",
        "    y_test_preds = clf.predict(X_test, W)\n",
        "    test_errors.append(clf.Ein(y_test_preds,y_test_true) * 100)\n",
        "\n",
        "  return test_errors, train_errors"
      ],
      "metadata": {
        "id": "y3sQyQxFgmXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_PLA_ITER = 700\n",
        "INTERVAL_SNAPSHOT = 50\n",
        "\n",
        "# fit\n",
        "pla_clf = OneVsAllPerceptron(MAX_PLA_ITER, INTERVAL_SNAPSHOT)\n",
        "pla_clf.fit(X_train, y_signed_train)\n",
        "\n",
        "#predict\n",
        "y_pred = pla_clf.predict(X_test)\n",
        "\n",
        "# plot convergence\n",
        "plot_multiclass_perceptron_convergence(pla_clf, INTERVAL_SNAPSHOT)"
      ],
      "metadata": {
        "id": "J_qDc00rMVe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "jM77wOW7MmS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass Classification Result**\n",
        "* accurency = âˆ‘TPáµ¢ / (numer of samples)\n",
        "* confustion matrix"
      ],
      "metadata": {
        "id": "0kJMMeGhYM0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accurency\n",
        "acc = accuracy_score(y_test_true, y_pred)\n",
        "print(f\"accurency: {100*acc} %\\n\")\n",
        "\n",
        "# multy class confusion matrix\n",
        "conf_mat = confusion_matrix(y_test_true, y_pred)\n",
        "plot_multiclass_confusion_matrix(conf_mat,\n",
        "                                 \"Confusion Matrix for Multi-class Perceptron Model\")"
      ],
      "metadata": {
        "id": "_VSoImtUNDTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Classifier Results** <br>\n",
        "For each classifier, we'll examine:\n",
        "\n",
        "* **Confustion matrix**\n",
        "\n",
        "* **Error progression graph** - visualizes how the classifier's error in sample and in test changes over the training iterations\n",
        "\n",
        "* **Accurancy** - percentage of correctly classified samples. Calculte by the formula: `(TP+TN)/(TP+TN+FP+FN)`\n",
        "\n",
        "* **Sensitivity** - percentage of actual positive samples that are correctly identified by the classifier. Calculte by the formula: `TP/(TP+FN)`"
      ],
      "metadata": {
        "id": "VCknsWfyYxxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper funcion to show the confiotion matrix and the pocket process side by side\n",
        "\n",
        "def plot_pocket_progress(ax, train_history, digit):\n",
        "  iterations, w_pocket_history , train_errors = zip(*train_history)\n",
        "  test_errors = calc_test_errors_during_train(w_pocket_history)\n",
        "\n",
        "  ax.plot(iterations, test_errors, marker=None, linestyle='-', color='blue', label='test')\n",
        "  ax.plot(iterations, train_errors, marker=None, linestyle='-', color='orange', label='train')\n",
        "  ax.set_title(f\"Mean error throughout training\")\n",
        "  ax.set_xlabel(f\"Iteration (snapshot every {INTERVAL_SNAPSHOT} iteration)\")\n",
        "  ax.set_ylabel(f\"Mean error(%)\")\n",
        "  ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
        "  ax.legend()\n",
        "\n",
        "def calc_test_errors_during_train(w_pocket_history):\n",
        "  w_pocket_history_np = np.array(w_pocket_history)\n",
        "  y_preds = np.sign(X_test @ w_pocket_history_np.T) # each row is pred for diff w\n",
        "  y_true = y_signed_test[:, digit]\n",
        "  test_errors = np.mean(y_preds != y_true[:, None], axis=0) * 100\n",
        "  return test_errors\n",
        "\n",
        "def plot_conf_mat(ax, conf_matrix, digit):\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "              xticklabels=[\"True\", \"False\"], yticklabels=[\"True\", \"False\"], ax=ax)\n",
        "  ax.set_title(f\"Confusion Matrix\")\n",
        "  ax.set_xlabel(\"Predicted Labels\")\n",
        "  ax.set_ylabel(\"Actual Labels\")"
      ],
      "metadata": {
        "id": "i4As-KZTU2Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers =  pla_clf.get_classifiers()\n",
        "acc_arr = []\n",
        "\n",
        "for digit in tqdm(range(10), desc='show result'):\n",
        "  digit_clf = classifiers[digit]\n",
        "  y_digit_pred = np.where(digit_clf.predict(X_test) == 1, 1, 0) # turn -1 to 0\n",
        "  y_digit_true = y_test_onehot[:, digit] # use the digit-col of y\n",
        "\n",
        "\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
        "\n",
        "  # confision matrix\n",
        "  conf_matrix = confusion_matrix(y_digit_true, y_digit_pred)\n",
        "  plot_conf_mat(axes[0], conf_matrix, digit)\n",
        "\n",
        "  # mean error progression throughout training\n",
        "  train_history = digit_clf.get_train_history()\n",
        "  plot_pocket_progress(axes[1], train_history, digit)\n",
        "\n",
        "  fig.suptitle(f\"Digit {digit}\", fontsize=16)\n",
        "  plt.subplots_adjust(wspace=0.3, top=0.8)\n",
        "  plt.show()\n",
        "\n",
        "  # accuracy\n",
        "  acc = accuracy_score(y_digit_true, y_digit_pred)\n",
        "  acc_arr.append(acc)\n",
        "  print(f'Accuracy(W{digit}) = {acc*100:.3f}%')\n",
        "\n",
        "  # sensitivity\n",
        "  sensitivity = recall_score(y_digit_true, y_digit_pred)\n",
        "  print(f'Sensitivity(W{digit}) = {sensitivity*100:.3f}%\\n\\n')"
      ],
      "metadata": {
        "id": "GpuzOnD3PIjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Average accurency** <br>\n",
        "It's worse pay attation to the fact that the avarge accurancy is mach better than the multiclass accurancy. <br>\n",
        "This show us one of the weekness of the one-ve-all stragety."
      ],
      "metadata": {
        "id": "98dsW3yxXkMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'avg accurency: {np.mean(acc_arr)*100:.3f}%')"
      ],
      "metadata": {
        "id": "llmEn77UT9WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter choice"
      ],
      "metadata": {
        "id": "Ym6AX1OXRDe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the graphs of the mean errors of the binary classifiers, it appears that most improvement occurs within the first 200-400 iterations. After that, the rate of change slows significantly.\n",
        "<br>\n",
        "In order to make sure that \"hard\" digit like 8 and 9 will also be able to converge, it seems like chosing **max_iter=1000** would be a good choice if we want to ensure all the digits converge.\n",
        "<br>\n",
        "However, if we take a close look on the mean loss of the multiclass classifer graph, we can see that ater 400 iteration, there is almost no change at all. So it might be that some of the digit still didnt fully converge, but for the multiclass clthis is meaningles.\n",
        "<br>\n",
        "Therefore, I chose `max_iter=700` as a good balance between performence and time.\n",
        "![image](https://drive.google.com/uc?export=view&id=1mDqaYCoXzKC4vBSmgyiymySJNaMuBjmk)\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "XV4WLzjKFmEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Discussion"
      ],
      "metadata": {
        "id": "b-GbVxD3RGCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Time:** <br>\n",
        " the perceptron model is computationally expensive, particularly when the dataset is large. This is further exacerbated when using the pocket model as each weight update requires recalculating the error, adding to the overall computational burden.\n",
        "\n",
        "* **Limited performance:** <br>\n",
        " Despite increasing the max_iter parameter, the performance of the perceptron model does not improve significantly (as shown in the graph above). This indicates that the model's performance is limited, and even with more computational resources, it may not achieve better results.\n",
        "\n",
        "* **One-VS-All Weekness:** <br>\n",
        " as we have seen, the multiclass classifier performs worse then the individual binary classifiers. This happens as a result of using a one-versus-all strategy that does not take into account more complex relationships between classes."
      ],
      "metadata": {
        "id": "p-KN1XCFUChm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ—» Logistic regration"
      ],
      "metadata": {
        "id": "JxzVVzilJ0mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, max_iter=500, learning_rate = 0.1, gradient_tresh = 1e-5, Ein_tresh = 0.5):\n",
        "    self.max_iter = max_iter\n",
        "    self.lr = learning_rate\n",
        "    self.gradient_tresh = gradient_tresh\n",
        "    self.Ein_tresh = Ein_tresh\n",
        "    self._w = None\n",
        "    self._train_history = []\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    m_samples, n_features = X.shape\n",
        "    k_classes = y.shape[1]\n",
        "\n",
        "    # W = (w0, w1, ... , w9) where weights distrbute with N(Î¼=0, Ïƒ^2=0.01)\n",
        "    self._W = np.random.normal(0, 0.01, (n_features, k_classes))\n",
        "\n",
        "    for epoch in tqdm(range(self.max_iter), desc= f'logistic regression'):\n",
        "\n",
        "      # improving W using the gradien desent method\n",
        "      grad = self._gradient(X, y)\n",
        "      self._W -= self.lr * grad\n",
        "\n",
        "      # record current\n",
        "      grad_norm = np.linalg.norm(grad)\n",
        "      loss = self.cross_entropy_loss(X, y)\n",
        "      self._train_history.append((epoch, grad_norm, loss))\n",
        "      # print(f\"Epoch: {epoch}, Loss: {loss}, Gradient Norm: {grad_norm}\")\n",
        "\n",
        "      # check if it is time to stop\n",
        "      if (grad_norm < self.gradient_tresh) and (loss < self.Ein_tresh):\n",
        "        break\n",
        "\n",
        "\n",
        "  def _gradient(self, X, y_one_hot):\n",
        "    P_hat = self.predict_proba(X)\n",
        "    return X.T @ (P_hat - y_one_hot) / X.shape[0]\n",
        "\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      matrix (m_samples,k). Where each row is the class probabilities for sample\n",
        "      for example the i-rows: [p(yi=1|xi), ... , p(yi=k|xi)] which is h(xi)^t\n",
        "    \"\"\"\n",
        "    score = X @ self._W\n",
        "    return self.softmax(score)\n",
        "\n",
        "\n",
        "  def softmax(self, score):\n",
        "    # for numerical stability - subtract the row-wise max of exps\n",
        "    shifted_score = score - np.max(score, axis=1, keepdims=True)\n",
        "\n",
        "    exp_scores = np.exp(shifted_score)\n",
        "    return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
        "\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.argmax(self.predict_proba(X), axis=1)\n",
        "\n",
        "\n",
        "  def cross_entropy_loss(self, X, y):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      Ein(w) = âˆ’(1/N) âˆ‘âˆ‘I[Yn=k]â‹…log(p(Yn=kâˆ£Xn))\n",
        "    \"\"\"\n",
        "    P_hat = self.predict_proba(X)\n",
        "\n",
        "    # to avoid log(0) - ensure probabilities are in the range [Îµ, 1-Îµ]\n",
        "    epsilon = 1e-15\n",
        "    P_hat_clipped = np.clip(P_hat, epsilon, 1 - epsilon)\n",
        "\n",
        "    # y is one-hot encodded, so multiplying it element-wise is equivalent to I[Yn=k]\n",
        "    loss = -np.mean(y * np.log(P_hat_clipped))\n",
        "    return loss\n",
        "\n",
        "  def get_W(self):\n",
        "    return self._W\n"
      ],
      "metadata": {
        "id": "-2NT4dTNJ6DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "lAs4euYajqEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper funcion to show to training procces\n",
        "\n",
        "def plot_logistic_convergence(clf):\n",
        "  epochs, grad_norms, losses = zip(*clf._train_history)\n",
        "  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "  # plot Mean Cross-Entropy Loss\n",
        "  plot_graph_on_ax(ax=ax1, x_axis=epochs, y_axis=losses,\n",
        "                   color='blue', label='Mean Cross-Entropy Loss',\n",
        "                   xlabel='Epoch', ylabel='Loss',\n",
        "                   title='Mean Cross-Entropy Loss Convergence')\n",
        "\n",
        "  # plot Gradient Norm\n",
        "  plot_graph_on_ax(ax=ax2, x_axis=epochs, y_axis=losses,\n",
        "                   color='orange', label='Gradient Norm',\n",
        "                   xlabel='Epoch', ylabel='Gradient Norm',\n",
        "                   title='Gradient Norm Convergence')\n",
        "\n",
        "  fig.suptitle(f\"logistic convergence\", fontsize=16)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_graph_on_ax(ax, x_axis, y_axis, color, label, xlabel, ylabel, title):\n",
        "  ax.plot(x_axis, y_axis, color=color, label=label)\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel(ylabel)\n",
        "  ax.set_title(title)\n",
        "  ax.legend()\n",
        "  ax.grid(True, linestyle='-',alpha=0.7)"
      ],
      "metadata": {
        "id": "XYsc40yYqd6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 1\n",
        "NORMALIZE = True\n",
        "GRADIENT_TRESHOLD = 1e-5\n",
        "E_IN_TRESHOLD = 0.5\n",
        "MAX_REG_ITER = 400\n",
        "\n",
        "# normelize data\n",
        "X_train_normalized = X_train / 255.0\n",
        "X_test_normalized = X_test / 255.0\n",
        "\n",
        "# fit\n",
        "clf = LogisticRegression(MAX_REG_ITER, LEARNING_RATE, GRADIENT_TRESHOLD, E_IN_TRESHOLD)\n",
        "clf.fit(X_train_normalized, y_train_onehot)\n",
        "\n",
        "# pred\n",
        "y_pred = clf.predict(X_test_normalized)\n",
        "\n",
        "# plot convergence\n",
        "plot_logistic_convergence(clf)"
      ],
      "metadata": {
        "id": "5PH_7OYhgklT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation"
      ],
      "metadata": {
        "id": "lXwNTAXBuaiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass Classification Result**\n",
        "\n",
        "* accurency = âˆ‘TPáµ¢ / (numer of samples)\n",
        "* confustion matrix"
      ],
      "metadata": {
        "id": "crNmmcCXhiGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accurency\n",
        "acc = accuracy_score(y_test_true, y_pred)\n",
        "print(f\"accurency: {100*acc} %\\n\")\n",
        "\n",
        "# multy class confusion matrix\n",
        "conf_mat = confusion_matrix(y_test_true, y_pred)\n",
        "plot_multiclass_confusion_matrix(conf_mat,\n",
        "                                 \"Confusion Matrix for Logistic Regration Model\")"
      ],
      "metadata": {
        "id": "IuvuaonEudor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Classifier Results** <br>\n",
        "For each classifier, we'll examine:\n",
        "\n",
        "* **Confustion matrix**\n",
        "\n",
        "* **Accurancy** - percentage of correctly classified samples. Calculte by the formula: `(TP+TN)/(TP+TN+FP+FN)`\n",
        "\n",
        "* **Sensitivity** - percentage of actual positive samples that are correctly identified by the classifier. Calculte by the formula: `TP/(TP+FN)`\n",
        "\n"
      ],
      "metadata": {
        "id": "WMkfipYAhmuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat_arr =[]\n",
        "\n",
        "print(f\"{'Digit':^7}|{'Accuracy':^13}|{'Sensitivity':^13}|\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "for digit in tqdm(range(10), desc='show result', leave=False):\n",
        "  digit_clf = classifiers[digit]\n",
        "  y_digit_pred = np.where(y_pred == digit, 1, 0)\n",
        "  y_digit_true = np.where(y_test_true == digit, 1, 0)\n",
        "  conf_mat_arr.append(confusion_matrix(y_digit_true, y_digit_pred))\n",
        "\n",
        "  # accuracy and sensitivity\n",
        "  acc = accuracy_score(y_digit_true, y_digit_pred)\n",
        "  sensitivity = recall_score(y_digit_true, y_digit_pred)\n",
        "  print(f\"{digit:^7}|{acc*100:^13.3f}|{sensitivity*100:^13.3f}|\")\n",
        "\n",
        "print(\"-\" * 35, \"\\n\")\n",
        "\n",
        "# table of confotion for each digit\n",
        "plot_confusion_matrices_side_by_side(conf_mat_arr, title=\"Confusion matrices - logistic regration\")"
      ],
      "metadata": {
        "id": "8cfLpIFGigsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameter choice"
      ],
      "metadata": {
        "id": "DGLHpHNoRwzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Learning Rate:** <br>\n",
        "Initially, I focused on finding  an appropriate learing rate. My goal was to find a lr whose convergence graph would be smooth.\n",
        "I tested different values of lr, as shown below, and found that `lr=1e-5` is the highest lr that gives smooth graph.\n",
        "![image](https://drive.google.com/uc?export=view&id=1eG4Hm5ErfiS3rGNXRjIYQ_ImTEKkGfyn)\n",
        "Therefor, I decided to try a different technique...\n",
        "\n",
        "* **Normalize** <br>\n",
        "To avoid such a small lr, I tried to normalizing the data by dividing by 255. With this approach, on the first try with lr=1, the model reached good accuracy and demonstrated smooth convergence with lr = 1, as showen above. Lower learning rates still produced good convergence but with lower accuracy, which led `lr=1` being the winning choise.\n",
        "\n",
        "* **gradient treshold** and **Ein treshold** <br>\n",
        " In order to ensure the model converged, both of these thresholds were set to small values. `gradient_treshold=1e-5`, so we will be close a possible to minmum. However I wanted to avoid overfitting on the training set, therefore I chose `Ein_treshold=0.5`. In both cases, these thresholds were never met, and the model always ran until the last epoch.\n",
        "\n",
        "* **max_iter** <br>\n",
        "We can see that the graph flattens out after about 300 iterations, with no significant improvement in performance as the iterations increase. To reduce runtime, I chose `max_iter=400`, which provided good accurancy while significantly cutting down the training time.\n",
        "![image](https://drive.google.com/uc?export=view&id=1P98DE4XjMd0VSrZl3ZhO0n_VRAOisi03)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XP7UOfboyd9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **lr cheking**"
      ],
      "metadata": {
        "id": "MPIv3WuU6ApY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# uncomment the cell in order to plot the graph of diffrent lr\n",
        "# warning: it takes lot of time!!\n",
        "'''\n",
        "\n",
        "# LR_CHEAK = True\n",
        "\n",
        "# if LR_CHEAK:\n",
        "#   lr_val = [1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
        "#   color_list = ['blue', 'green', 'red', 'cyan', 'magenta', 'orange', 'purple']\n",
        "#   accuracy_val = []\n",
        "#   max_iter = 300\n",
        "\n",
        "\n",
        "#   fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "#   for idx in tqdm(range(len(lr_val)), desc=\"lr vals\"):\n",
        "\n",
        "#     # fit\n",
        "\n",
        "#     clf_lr = LogisticRegression(max_iter, lr_val[idx], GRADIENT_TRESHOLD, E_IN_TRESHOLD)\n",
        "#     clf_lr.fit(X_train, y_train_onehot)\n",
        "\n",
        "#     # pred\n",
        "#     y_pred = clf.predict(X_test)\n",
        "\n",
        "#     # add graph\n",
        "#     epochs, grad_norms, losses = zip(*clf_lr._train_history)\n",
        "#     ax1.plot(epochs, grad_norms, label=f'lr={lr_val[idx]}', color=color_list[idx])\n",
        "#     ax2.plot(epochs, losses, label=f'lr={lr_val[idx]}', color=color_list[idx])\n",
        "\n",
        "#     accuracy_val.append(100*accuracy_score(y_test_true, y_pred))\n",
        "\n",
        "#   # Gradient Norm Plot\n",
        "#   ax1.set_xlabel('Epoch')\n",
        "#   ax1.set_ylabel('Gradient Norm')\n",
        "#   ax1.set_title('Gradient Norm Convergence')\n",
        "#   ax1.legend()\n",
        "#   ax1.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "#   # Loss Plot\n",
        "#   ax2.set_xlabel('Epoch')\n",
        "#   ax2.set_ylabel('Loss')\n",
        "#   ax2.set_title('Loss Convergence ')\n",
        "#   ax2.legend()\n",
        "#   ax2.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "#   plt.tight_layout()\n",
        "#   plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ab0cMJLNyov-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Discussion"
      ],
      "metadata": {
        "id": "VfLiOOmuRzkP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* **Performance:** <br>\n",
        "The model manages to provide better performance than the perceptron: logistic regression achieved an accuracy of around 91%, compared to 88% approximately for the perceptron. Additionally, the sensitivity of each digit is higher with the logistic regration. This suggesting that the data may be separable by non-linear boundaries.\n",
        "\n",
        "* **Convergence:** <br>\n",
        "the model required a very low learning rate or normalization the data, indicating that there is some noise in the data that needs to be corrected. Which may make it difficult to achieve a full separation between the digits\n",
        "\n",
        "* **Time:** <br>\n",
        "The runtime is slightly shorter than the perceptron (3 minutes instead of 4 minutes on my home computer). However, the model still requires a considerable amount of time to converge.\n",
        "\n",
        "<br><br>\n",
        "Overall, logistic regression provided better results with similar training times to the perceptron, making it a more effective model for this task."
      ],
      "metadata": {
        "id": "_e5cPrd_0rQX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ“ˆ Linear Regression"
      ],
      "metadata": {
        "id": "HtdPTA802Xq5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self):\n",
        "    self.w = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Use pseudo-inverse\n",
        "    # W = (Xáµ€X)-1y\n",
        "    self.w = np.linalg.pinv(X.T @ X) @ X.T @ y\n",
        "\n",
        "  def predict(self, X):\n",
        "    return X @ self.w\n",
        "\n",
        "  def loss(self, X, y):\n",
        "    return np.mean((self.predict(X) - y)**2)\n",
        "\n",
        "  def get_w(self):\n",
        "    return self.w"
      ],
      "metadata": {
        "id": "YW6mHFwZ2alq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## regular run\n",
        "First, let's try using linear regression in the classic way.\n",
        "Since linear regression gives a continuous prediction, we round each number to the nearest whole number to get the prediction."
      ],
      "metadata": {
        "id": "htm0EgRM4Gl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LinearRegression()\n",
        "clf.fit(X_train, y_train_true)\n",
        "\n",
        "y_pred = np.round(clf.predict(X_test))\n",
        "\n",
        "print(f\"accurency: {100*accuracy_score(y_test_true, y_pred)} %\")"
      ],
      "metadata": {
        "id": "Le4OtR0t_DhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This approach did not work well and gave us poor results. <br>\n",
        "This is because linear regression assumes a simple, straight-line relationship between the features and the classes. However multiclass classification problems are more complex than that. <br>\n",
        "Consequently, the approximately the ~20% accuracy achieved by this simple linear regression approach is essentially equivalent to random chance"
      ],
      "metadata": {
        "id": "V2_ZnpwsD1Oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## one vs all\n",
        "Similar to the Perceptron implementation, we can employ a one-vs-all strategy for linear regression where we train a separate linear regression model for each digit (0-9). Instead of using the direct output of the linear regression model (wáµ€x) as the prediction, we treat it as a **\"match score\"** for the corresponding digit. Therefore, the hypothesis function for this approach becomes: `(x) = argmax(wáµ€x)`\n"
      ],
      "metadata": {
        "id": "0tu43iR3_UQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneVsAllLinearRegration:\n",
        "  def __init__(self):\n",
        "    self._W = None\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    W = np.empty((X_train.shape[1],0)) # W = (w0, w1, ... , w9)\n",
        "    k_classes = Y.shape[1]\n",
        "\n",
        "    for digit in tqdm(range(k_classes), desc='Single digit linear regration'):\n",
        "      # use the digit-th column of Y\n",
        "      y_digit = Y[:, digit]\n",
        "\n",
        "      # create Wi using linear regration\n",
        "      clf = LinearRegression()\n",
        "      clf.fit(X, y_digit)\n",
        "      W = np.column_stack([W, clf.get_w()])\n",
        "    self._W = W\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.argmax(X @ self._W, axis=1)\n",
        "\n",
        "  def get_W(self):\n",
        "    return self._W"
      ],
      "metadata": {
        "id": "LBwVyEoi4G4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "clf = OneVsAllLinearRegration()\n",
        "clf.fit(X_train, y_signed_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "# print(f\"accurency: {100*accuracy_score(y_test_true, y_pred)} %\")"
      ],
      "metadata": {
        "id": "G-jKSWdN8k5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n"
      ],
      "metadata": {
        "id": "3YMNa9dSHo3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multiclass Classification Result**\n",
        "* accurency = âˆ‘TPáµ¢ / (numer of samples)\n",
        "* confustion matrix"
      ],
      "metadata": {
        "id": "U8JWj2pdG_Cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# accurency\n",
        "acc = accuracy_score(y_test_true, y_pred)\n",
        "print(f\"accurency: {100*acc} %\\n\")\n",
        "\n",
        "# multy class confusion matrix\n",
        "conf_mat = confusion_matrix(y_test_true, y_pred)\n",
        "plot_multiclass_confusion_matrix(conf_mat,\n",
        "                                 \"Confusion Matrix for One-VS-All Linear Regrassion \")"
      ],
      "metadata": {
        "id": "amhg1VUNHAOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binary Classifier Results** <br>\n",
        "For each classifier, we'll examine:\n",
        "\n",
        "* **Confustion matrix**\n",
        "\n",
        "* **Accurancy** - percentage of correctly classified samples. Calculte by the formula: `(TP+TN)/(TP+TN+FP+FN)`\n",
        "\n",
        "* **Sensitivity** - percentage of actual positive samples that are correctly identified by the classifier. Calculte by the formula: `TP/(TP+FN)`\n"
      ],
      "metadata": {
        "id": "DyRO4C2EHsNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat_arr =[]\n",
        "\n",
        "print(f\"{'Digit':^7}|{'Accuracy':^13}|{'Sensitivity':^13}|\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "for digit in tqdm(range(10), desc='show result', leave=False):\n",
        "  digit_clf = classifiers[digit]\n",
        "  y_digit_pred = np.where(y_pred == digit, 1, 0)\n",
        "  y_digit_true = np.where(y_test_true == digit, 1, 0)\n",
        "  conf_mat_arr.append(confusion_matrix(y_digit_true, y_digit_pred))\n",
        "\n",
        "  # accuracy and sensitivity\n",
        "  acc = accuracy_score(y_digit_true, y_digit_pred)\n",
        "  sensitivity = recall_score(y_digit_true, y_digit_pred)\n",
        "  print(f\"{digit:^7}|{acc*100:^13.3f}|{sensitivity*100:^13.3f}|\")\n",
        "\n",
        "print(\"-\" * 35, \"\\n\")\n",
        "\n",
        "# table of confotion for each digit\n",
        "plot_confusion_matrices_side_by_side(conf_mat_arr, title=\"Confusion matrices - logistic regration\")"
      ],
      "metadata": {
        "id": "oqBc3bE4H51V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result Discussion"
      ],
      "metadata": {
        "id": "uP5MXDOxH-_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **performnce and time:** <br>\n",
        "This approach achieved an accuracy of around 84% with minimal computational time, marking a significant improvement compared to the standard linear regression, which only reached around 20% accuracy. This is impressive, especially considering that both the Perceptron and linear regression models took several minutes to reach similar accuracy levels.\n",
        "\n",
        "* **No future improvement:**<br>\n",
        "Unlike the Perceptron and Logistic Regression models, where the weights are adjusted iteratively, the one-vs-all linear regression calculates the weights directly. The result that is reached is final and cannot be improved.\n",
        "\n",
        "However, the weights obtained from this method could serve as a starting point for the Perceptron or for the Logistic Regression. Initializing these models with those weights might reduce their training time, as they would be starting from a good point.\n",
        "\n"
      ],
      "metadata": {
        "id": "JApolONHIA0Q"
      }
    }
  ]
}